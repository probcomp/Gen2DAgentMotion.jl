############################################
# hand-coded dynamic programming inference #
############################################

# the observed points are generated by walking along the 
# path at a nominal speed, with random pauses and skips

@inline function noise_log_likelihood(params::ObsModelParams, location::Point, obs_pt::Point)
    ll = logpdf(normal, obs_pt.x, location.x, params.noise)
    ll += logpdf(normal, obs_pt.y, location.y, params.noise)
    return ll
end

@inline function compute_alpha_entry(params::ObsModelParams, location::Point, obs::Point, prev_alpha, k::Int)
    # observation model: obs corresponds with points_along_path
    noise_ll = noise_log_likelihood(params, location, obs)

    # dynamics model: given that we are k, the previous could have been
    # (i) k - 2 (skip one), (ii) k - 1 (advance as usual), or (iii) k
    # (don't advance, lag)
    if k > 2
        val1 = prev_alpha[k-2] + log(prob_skip(params))
    else
        val1 = -Inf
    end
    if k > 1
        val2 = prev_alpha[k-1] + log(prob_normal(params))
    else
        val2 = -Inf
    end
    val3 = prev_alpha[k] + log(prob_lag(params))
    if val1 == -Inf && val2 == -Inf && val3 == -Inf
        return -Inf
    end
    max_val = max(val1, val2, val3)

    # combine observation and dynamics terms
    return noise_ll + max_val + log(exp(val1 - max_val) + exp(val2 - max_val) + exp(val3 - max_val))
end

@inline function populate_new_alpha!(
        new_alpha, prev_alpha, points_along_path::AbstractVector{Point}, obs_t::Point, params::ObsModelParams)
    @assert length(new_alpha) == length(points_along_path)
    @assert length(prev_alpha) == length(points_along_path)
    for k in 1:length(points_along_path)
        new_alpha[k] = compute_alpha_entry(params, points_along_path[k], obs_t, prev_alpha, k)
    end
    return nothing
end

@inline function forward_transition_log_probs(next_z::Int, params::ObsModelParams, K::Int)
    log_probs = fill(-Inf, K)
    if next_z == 1
        log_probs[1] = log(prob_lag(params))
    elseif next_z == 2
        log_probs[1] = log(prob_normal(params))
        log_probs[2] = log(prob_lag(params))
    else
        log_probs[next_z] = log(prob_lag(params))
        log_probs[next_z-1] = log(prob_normal(params))
        log_probs[next_z-2] = log(prob_skip(params))
    end
    return log_probs
end

@inline function populate_initial_alpha!(
        alpha, params::ObsModelParams, points_along_path::AbstractVector{Point}, obs1::Point)
    @assert length(alpha) == length(points_along_path)
    fill!(alpha, -Inf)
    # always starts at the first location
    alpha[1] = 0.0 + noise_log_likelihood(params, points_along_path[1], obs1)
    return nothing
end

# non-incremental forward algorithm
function forward_filtering(
        params::ObsModelParams, points_along_path::AbstractVector{Point}, obs::AbstractVector{Point})

    K = length(points_along_path)
    T = length(obs)

    # allocate memory
    alphas = Vector{Vector{Float64}}(undef, T)
    for t in 1:T
        alphas[t] = Vector{Float64}(undef, K)
    end

    populate_initial_alpha!(alphas[1], params, points_along_path, obs[1])
    for t in 2:T
        populate_new_alpha!(alphas[t], alphas[t-1], points_along_path, obs[t], params)
    end
    log_marginal_likelihood = logsumexp(alphas[T])

    # make persistent
    alphas_persistent_vec = Vector{PersistentVector{Float64}}(undef, T)
    for t in 1:T
        alphas_persistent_vec[t] = PersistentVector{Float64}(alphas[t])
    end
    alphas_persistent = PersistentVector{PersistentVector{Float64}}(alphas_persistent_vec)
    return (alphas_persistent, log_marginal_likelihood)
end

# backwards sampling, given alphas from forward algorithm
function backwards_sampling(
        params::ObsModelParams, points_along_path::Vector{Point}, obs::Vector{Point},
        alphas)

    K = length(points_along_path)
    T = length(obs)

    alignment = Vector{Int}(undef, length(points_along_path))
    ldist = alphas[T]
    dist = exp.(ldist .- logsumexp(ldist))
    alignment[T] = categorical(dist)
    for t in T-1:-1:1
        ldist = alphas[t] .+ forward_transition_log_probs(alignment[t+1], params, K)
        dist = exp.(ldist .- logsumexp(ldist))
        alignment[t] = categorical(dist)
    end
    return alignment
end

# forward computation that does not retain alphas
# (and therefore cannot be used for backwards samping
# or incrementally doing forward algorithm)
function log_marginal_likelihood(
        params::ObsModelParams,
        path::Vector{Point},
        measurements::AbstractVector{Point})

    T = length(measurements)
    (dp_points_along_path, dp_progress) = walk_path(path, params.nominal_speed, num_hidden_states(T))
    K = length(dp_points_along_path)
    alpha = Vector{Float64}(undef, K)
    new_alpha = Vector{Float64}(undef, K)
    populate_initial_alpha!(alpha, params, dp_points_along_path, measurements[1])
    for t in 2:T
        populate_new_alpha!(new_alpha, alpha, dp_points_along_path, measurements[t], params)
        tmp = alpha; alpha = new_alpha; new_alpha = tmp
    end
    return logsumexp(alpha)
end

# incremental forward algorithm
function forward_filtering_incremental(
        params::ObsModelParams,
        points_along_path::AbstractVector{Point}, obs::AbstractVector{Point},
        alphas::PersistentVector{PersistentVector{Float64}})

    @assert length(alphas) > 0

    # this would require a different enough code path that I am just using the
    # non-incremental version; since there is one time step, there is not likely
    # to be any speedup due to incrementalization anyways
    if length(alphas) == 1
        return forward_filtering(params, points_along_path, obs)
    end

    # new observation; we will increment number of columns by one
    T = length(obs)
    new_obs = obs[T]

    # new point along path; we will increment the number of rows by one
    K_prev = length(alphas[1])
    K_new = length(points_along_path)
    new_alphas = alphas
    for K in (K_prev+1):K_new
        new_point_along_path = points_along_path[K]
        # first, compute new row for the new points along the path (i.e. new hidden states)
        new_alphas = assoc(new_alphas, 1, push(new_alphas[1], -Inf))
        for t in 2:(T-1)
            new_alphas_t = push(new_alphas[t], compute_alpha_entry(params, new_point_along_path, obs[t], new_alphas[t-1], K))
            new_alphas = assoc(new_alphas, t, new_alphas_t)
        end
    end

    # next, compute new column for the new observation
    new_alpha_T = Vector{Float64}(undef, K_new)
    populate_new_alpha!(
        new_alpha_T, new_alphas[T-1], points_along_path, new_obs, params)
    new_alphas = push(new_alphas, PersistentVector{Float64}(new_alpha_T))

    # could be incrementalized, but is already just O(K)
    log_marginal_likelihood = logsumexp(new_alphas[T])

    return (new_alphas, log_marginal_likelihood)
end

# TODO test me -- can check that importance sampling deterministically gives the marginal likelihood

@gen function sample_locations_exact_conditional(
        params::ObsModelParams,
        path::AbstractVector{Point},
        measurements::AbstractVector{Point})
    T = length(measurements)
    (dp_points_along_path, dp_progress) = walk_path(path, params.nominal_speed, num_hidden_states(T))
    K = length(dp_points_along_path)
    (alphas, _) = forward_filtering(params, dp_points_along_path, measurements)
    T = length(measurements)
    alignment = Vector{Int}(undef, T)
    ldist = alphas[T]
    dist = exp.(ldist .- logsumexp(ldist))
    alignment[T] = ({(:alignment, T)} ~ categorical(dist))
    for t in T-1:-1:1
        ldist = alphas[t] .+ forward_transition_log_probs(alignment[t+1], params, K)
        dist = exp.(ldist .- logsumexp(ldist))
        alignment[t] = ({(:alignment, t)} ~ categorical(dist))
    end
    @assert alignment[1] == 1
    locations = Vector{Point}(undef, T)
    for t in 1:T
        locations[t] = dp_points_along_path[alignment[t]]
    end
    return locations
end
